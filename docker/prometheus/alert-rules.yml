# ===========================================
# Prometheus Alert Rules
# ===========================================

groups:
  # ===========================================
  # Application Health Alerts
  # ===========================================
  - name: application-alerts
    rules:
      # -------------------------------------------
      # 애플리케이션 다운 알림
      # -------------------------------------------
      - alert: ApplicationDown
        expr: up{job="spring-boot-app"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Application is down"
          description: "Spring Boot application {{ $labels.instance }} has been down for more than 1 minute."

      # -------------------------------------------
      # 높은 에러율 알림
      # -------------------------------------------
      - alert: HighErrorRate
        expr: |
          sum(rate(http_server_requests_seconds_count{status=~"5.."}[5m])) 
          / 
          sum(rate(http_server_requests_seconds_count[5m])) > 0.05
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High error rate detected"
          description: "Error rate is above 5% for the last 5 minutes."

      # -------------------------------------------
      # 느린 응답 시간 알림
      # -------------------------------------------
      - alert: SlowResponseTime
        expr: |
          histogram_quantile(0.95, 
            sum(rate(http_server_requests_seconds_bucket[5m])) by (le)
          ) > 2
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Slow response time detected"
          description: "95th percentile response time is above 2 seconds."

  # ===========================================
  # JVM Health Alerts
  # ===========================================
  - name: jvm-alerts
    rules:
      # -------------------------------------------
      # 높은 메모리 사용량 알림
      # -------------------------------------------
      - alert: HighMemoryUsage
        expr: |
          (jvm_memory_used_bytes{area="heap"} 
          / 
          jvm_memory_max_bytes{area="heap"}) > 0.85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High JVM heap memory usage"
          description: "JVM heap memory usage is above 85% for {{ $labels.instance }}."

      # -------------------------------------------
      # 매우 높은 메모리 사용량 (Critical)
      # -------------------------------------------
      - alert: CriticalMemoryUsage
        expr: |
          (jvm_memory_used_bytes{area="heap"} 
          / 
          jvm_memory_max_bytes{area="heap"}) > 0.95
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Critical JVM heap memory usage"
          description: "JVM heap memory usage is above 95% for {{ $labels.instance }}. Immediate attention required!"

      # -------------------------------------------
      # 높은 GC 시간 알림
      # -------------------------------------------
      - alert: HighGCTime
        expr: |
          rate(jvm_gc_pause_seconds_sum[5m]) 
          / 
          rate(jvm_gc_pause_seconds_count[5m]) > 0.5
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High GC pause time"
          description: "Average GC pause time is above 500ms for {{ $labels.instance }}."

  # ===========================================
  # Infrastructure Alerts
  # ===========================================
  - name: infrastructure-alerts
    rules:
      # -------------------------------------------
      # Prometheus 타겟 다운
      # -------------------------------------------
      - alert: PrometheusTargetDown
        expr: up == 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Prometheus target is down"
          description: "{{ $labels.job }} target {{ $labels.instance }} has been down for more than 2 minutes."

      # -------------------------------------------
      # Alertmanager 다운
      # -------------------------------------------
      - alert: AlertmanagerDown
        expr: up{job="alertmanager"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Alertmanager is down"
          description: "Alertmanager has been down for more than 1 minute."

      # -------------------------------------------
      # Loki 다운
      # -------------------------------------------
      - alert: LokiDown
        expr: up{job="loki"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Loki is down"
          description: "Loki has been down for more than 1 minute."